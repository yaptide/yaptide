from yaptide.celery.worker import celery_app

from yaptide.persistence.models import SimulationModel

from yaptide.utils.sim_utils import (
    pymchelper_output_to_json,
    write_input_files,
    simulation_logfile,
    simulation_input_files,
    sh12a_simulation_status
)

from pathlib import Path
import tempfile
import os

from datetime import datetime

from celery.result import AsyncResult

from pymchelper.executor.options import SimulationSettings
from pymchelper.executor.runner import Runner as SHRunner


@celery_app.task(bind=True)
def run_simulation(self, json_data: dict):
    """Simulation runner"""
    # create temporary directory
    with tempfile.TemporaryDirectory() as tmp_dir_path:

        # digest dictionary with project data (extracted from JSON file)
        # and generate simulation input files
        input_files = write_input_files(json_data, Path(tmp_dir_path))
        # we assume here that the simulation executable is available in the PATH so pymchelper will discover it
        settings = SimulationSettings(input_path=tmp_dir_path,  # skipcq: PYL-W0612
                                      simulator_exec_path=None,
                                      cmdline_opts="")

        # Pymchelper uses all available cores by default
        ntasks = json_data["ntasks"] if json_data["ntasks"] > 0 else None

        runner_obj = SHRunner(jobs=ntasks,
                              keep_workspace_after_run=True,
                              output_directory=tmp_dir_path)

        self.update_state(state="PROGRESS", meta={"path": tmp_dir_path, "sim_type": json_data["sim_type"]})
        try:
            is_run_ok = runner_obj.run(settings=settings)
            if not is_run_ok:
                raise Exception
        except Exception:  # skipcq: PYL-W0703
            logfile = simulation_logfile(path=Path(tmp_dir_path, "run_1", "shieldhit_0001.log"))
            input_files = simulation_input_files(path=tmp_dir_path)
            return {"logfile": logfile, "input_files": input_files}

        estimators_dict: dict = runner_obj.get_data()

        result: dict = pymchelper_output_to_json(estimators_dict)

        return {
            "result": result,
            "input_json": json_data["sim_data"] if "metadata" in json_data["sim_data"] else None,
            "input_files": input_files,
            "end_time": datetime.utcnow(),
            "job_tasks_status": sh12a_simulation_status(dir_path=tmp_dir_path, sim_ended=True)
        }


@celery_app.task
def convert_input_files(json_data: dict):
    """Function converting output"""
    with tempfile.TemporaryDirectory() as tmp_dir_path:
        input_files = write_input_files(json_data, Path(tmp_dir_path))
        return {"input_files": input_files}


@celery_app.task
def simulation_task_status(job_id: str) -> dict:
    """Task responsible for returning simulation status"""
    job = AsyncResult(id=job_id, app=celery_app)
    job_state = job.state
    result = {
        "job_state": translate_celery_state_naming(job_state)
    }
    if job_state == "PENDING":
        pass
    elif job_state == "PROGRESS":
        if not job.info.get("sim_type") in {"shieldhit", "sh_dummy"}:
            return result
        sim_info = sh12a_simulation_status(dir_path=job.info.get("path"))
        result["job_tasks_status"] = sim_info
    elif job_state != "FAILURE":
        if "result" in job.info:
            for key in ["result", "input_files", "input_json", "end_time", "job_tasks_status"]:
                result[key] = job.info[key]
        elif "logfile" in job.info:
            result["job_state"] = translate_celery_state_naming("FAILURE")
            result["error"] = "Simulation error"
            result["logfile"] = job.info.get("logfile")
            result["input_files"] = job.info.get("input_files")
    else:
        result["error"] = str(job.info)

    return result


def xD():
    ROOT_DIR = Path(__file__).parent.resolve()
    FILENAME = "shieldhit.log"

    FILE = ROOT_DIR / FILENAME

    def follow(thefile):
        thefile.seek(0, os.SEEK_END) # End-of-file
        while True:
            line = thefile.readline()
            if not line:
                time.sleep(1) # Sleep briefly
                continue
            yield line

    logfile = open(FILE)
    loglines = follow(logfile)
    print(f"Following file: {FILE}")
    for line in loglines:
        print(line, end='')


@celery_app.task
def get_input_files(job_id: str) -> dict:
    """Task responsible for returning simulation input files generated by converter"""
    job = AsyncResult(id=job_id, app=celery_app)

    if job.state == "PROGRESS":
        result = {"info": "Input files"}
        input_files = simulation_input_files(job.info.get("path"))
        for key, value in input_files.items():
            result[key] = value
        return result
    return {"info": "No input present"}


@celery_app.task
def cancel_simulation(job_id: str) -> bool:
    """Task responsible for canceling simulation in progress"""
    # Currently this task does nothing because to working properly it requires changes in pymchelper
    print(job_id)
    return False


def translate_celery_state_naming(job_state: str) -> str:
    """Function translating celery states' names to ones used in YAPTIDE"""
    if job_state in ["RECEIVED", "RETRY"]:
        return SimulationModel.JobStatus.PENDING.value
    if job_state in ["PROGRESS", "STARTED"]:
        return SimulationModel.JobStatus.RUNNING.value
    if job_state in ["FAILURE", "REVOKED"]:
        return SimulationModel.JobStatus.FAILED.value
    if job_state in ["SUCCESS"]:
        return SimulationModel.JobStatus.COMPLETED.value
    # Others are the same
    return job_state
